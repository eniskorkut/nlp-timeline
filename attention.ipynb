{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attention Örnek Kodu\n",
    "import numpy as np\n",
    "\n",
    "# Basit bir girdi dizisi simüle edelim (örneğin, 3 kelimelik bir cümle, her kelime 4 boyutlu bir vektörle temsil ediliyor)\n",
    "# Girdi Matrisi (Şekil: dizi uzunluğu, embedding boyutu)\n",
    "# Kelime 1, Kelime 2, Kelime 3\n",
    "input_sequence = np.array([\n",
    "    [1.0, 0.5, 0.1, 0.8], # Kelime 1 vektörü\n",
    "    [0.2, 0.7, 0.9, 0.3], # Kelime 2 vektörü (belki \"önemli\" bir kelime)\n",
    "    [0.6, 0.4, 0.7, 0.5]  # Kelime 3 vektörü\n",
    "])\n",
    "\n",
    "print(\"Girdi Dizisi (Simüle Edilmiş Kelime Vektörleri):\")\n",
    "print(input_sequence)\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Senaryo 1: Attention Mekanizması Yok (Basit Ortalama veya Sabit Ağırlıklandırma)\n",
    "# Bu senaryoda, her kelime çıktıya eşit veya sabit bir ağırlıkla katkıda bulunur.\n",
    "# En basit haliyle ortalama alma.\n",
    "\n",
    "output_no_attention = np.mean(input_sequence, axis=0)\n",
    "\n",
    "print(\"Attention Olmayan Çıktı (Basit Ortalama):\")\n",
    "print(output_no_attention)\n",
    "print(\"Açıklama: Her kelime çıktıya eşit derecede katkıda bulundu.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# Senaryo 2: Attention Mekanizması Var (Basit Bir Dikkat Simülasyonu)\n",
    "# Attention, hangi girdi öğelerinin çıktı için daha önemli olduğuna karar verir\n",
    "# ve onlara daha yüksek ağırlıklar atar.\n",
    "# Bu ağırlıklar, model tarafından öğrenilir ve hangi kelimenin (pozisyonun)\n",
    "# çıktı için ne kadar önemli olduğunu gösterir. Toplamları 1'e eşittir.\n",
    "# Örneğin, 2. kelimenin daha önemli olduğunu varsayalım (indeks 1).\n",
    "attention_weights = np.array([0.2, 0.6, 0.2]) # Kelime 1, Kelime 2, Kelime 3 için ağırlıklar\n",
    "\n",
    "# Dikkat ağırlıklarını girdi dizisine uygulayalım (ağırlıklı toplam)\n",
    "# Her kelime vektörünü kendi dikkat ağırlığı ile çarpıp topluyoruz.\n",
    "output_with_attention = np.sum(input_sequence * attention_weights[:, np.newaxis], axis=0)\n",
    "\n",
    "print(\"Attention İle Çıktı (Ağırlıklı Toplam):\")\n",
    "print(output_with_attention)\n",
    "print(f\"Kullanılan Dikkat Ağırlıkları: {attention_weights}\")\n",
    "print(\"Açıklama: Çıktı, dikkat ağırlıklarına göre kelimelerin ağırlıklı toplamıdır.\")\n",
    "print(\"Daha yüksek ağırlığa sahip kelimeler (burada Kelime 2) çıktı üzerinde daha fazla etkiye sahiptir.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Karşılaştırma\n",
    "print(\"Karşılaştırma:\")\n",
    "print(\"Attention Olmayan Çıktı:\", output_no_attention)\n",
    "print(\"Attention İle Çıktı:   \", output_with_attention)\n",
    "print(\"\\nFarklılıklar, attention'ın girdi vektörlerini önemlerine göre yeniden ağırlıklandırmasından kaynaklanır.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# df_reviews DataFrame'ini kullanıyoruz (veri yükleme adımından)\n",
    "# Eğer bu hücreyi tek başına çalıştırıyorsanız, df_reviews'ı tekrar yüklemeniz gerekebilir.\n",
    "\n",
    "if 'df_reviews' in locals() and not df_reviews.empty:\n",
    "    # 'Metin' sütununu bilgi kaynağı olarak alalım\n",
    "    knowledge_source = df_reviews['Metin'].tolist()\n",
    "\n",
    "    print(f\"Bilgi Kaynağına Eklenen Yorum Sayısı: {len(knowledge_source)}\")\n",
    "    print(\"\\nBilgi Kaynağından İlk 5 Yorum:\")\n",
    "    for i, review in enumerate(knowledge_source[:5]):\n",
    "        print(f\"{i+1}. {review}\")\n",
    "\n",
    "else:\n",
    "    print(\"df_reviews DataFrame'i bulunamadı veya boş. Lütfen veri yükleme adımını çalıştırın.\")"
   ],
   "id": "8e76e9f6d5a00936"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
