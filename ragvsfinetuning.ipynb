{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install evaluate",
   "id": "e30b433e7ecf61b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Yüklenen veri setinin yolu\n",
    "csv_file_path = \"/content/e-ticaret_urun_yorumlari.csv\" # Dosya yolunu düzelttik\n",
    "\n",
    "# CSV dosyasını pandas DataFrame'e yükleyelim\n",
    "try:\n",
    "    # Ayırıcıyı noktalı virgül (';') olarak belirtelim ve hatalı satırları atlayalım\n",
    "    df_reviews = pd.read_csv(csv_file_path, sep=';', on_bad_lines='skip')\n",
    "\n",
    "\n",
    "    # İlk birkaç satırını görüntüleyelim\n",
    "    print(\"Veri Seti (İlk 5 Satır):\")\n",
    "    display(df_reviews.head())\n",
    "\n",
    "    # Veri seti hakkında genel bilgi alalım (sütunlar, veri tipleri, eksik değerler)\n",
    "    print(\"\\nVeri Seti Bilgisi:\")\n",
    "    df_reviews.info()\n",
    "\n",
    "    # Sütun adlarını kontrol edelim (Bilindiği için doğrudan kullanacağız)\n",
    "    text_column_name = 'Metin'\n",
    "    label_column_name = 'Durum'\n",
    "    print(f\"\\nMetin Sütunu Adı: {text_column_name}\")\n",
    "    print(f\"Etiket Sütunu Adı: {label_column_name}\")\n",
    "\n",
    "    # Etiket dağılımına bakalım\n",
    "    if label_column_name in df_reviews.columns:\n",
    "        print(f\"\\n'{label_column_name}' Sütunu Dağılımı:\")\n",
    "        print(df_reviews[label_column_name].value_counts())\n",
    "        # Burada num_labels ve label_map'i fine-tuning adımı için saklayabiliriz\n",
    "        unique_labels = df_reviews[label_column_name].unique()\n",
    "        # np.int64 objelerini int'e dönüştürelim\n",
    "        label_map = {int(label): i for i, label in enumerate(unique_labels)}\n",
    "        num_labels = len(unique_labels)\n",
    "        print(f\"\\nEtiket Eşlemesi (Fine-tuning için): {label_map}\")\n",
    "        print(f\"Toplam Etiket Sayısı (Fine-tuning için): {num_labels}\")\n",
    "\n",
    "    else:\n",
    "        # Bu durum normalde olmamalı çünkü sütun adlarını doğrudan kullandık,\n",
    "        # ama hata kontrolü için burada bırakılabilir veya kaldırılabilir.\n",
    "        print(f\"\\nHata: '{label_column_name}' sütunu veri setinde bulunamadı.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Hata: {csv_file_path} bulunamadı. Lütfen dosya yolunu kontrol edin.\")\n",
    "except Exception as e:\n",
    "    print(f\"Veri seti yüklenirken bir hata oluştu: {e}\")"
   ],
   "id": "132d3afcaf37584d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Yüklenen veri setinin yolu (bir önceki adımdan)\n",
    "csv_file_path = \"/content/e-ticaret_urun_yorumlari.csv\"\n",
    "\n",
    "# CSV dosyasını pandas DataFrame'e yükleyelim (bir önceki adımdan)\n",
    "try:\n",
    "    # Ayırıcıyı noktalı virgül (';') olarak belirtelim ve hatalı satırları atlayalım\n",
    "    df_reviews = pd.read_csv(csv_file_path, sep=';', on_bad_lines='skip')\n",
    "    print(\"Veri seti başarıyla yüklendi.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Hata: {csv_file_path} bulunamadı. Lütfen dosya yolunu kontrol edin.\")\n",
    "    df_reviews = None\n",
    "except Exception as e:\n",
    "    print(f\"Veri seti yüklenirken bir hata oluştu: {e}\")\n",
    "    df_reviews = None\n",
    "\n",
    "\n",
    "# df_reviews'ın yüklenip yüklenmediğini kontrol edelim\n",
    "if df_reviews is not None and not df_reviews.empty:\n",
    "    # Sütun adları 'Metin' ve 'Durum' olarak bilindiği için doğrudan kullanalım.\n",
    "    text_column = 'Metin' # Metin sütununun adı\n",
    "    label_column = 'Durum' # Etiket/Duygu sütununun adı\n",
    "\n",
    "    # Sadece ilgili sütunları seçelim ve eksik değerleri temizleyelim (varsa)\n",
    "    df_cleaned = df_reviews[[text_column, label_column]].dropna().copy()\n",
    "\n",
    "    # Etiket sütununun adını 'labels' olarak değiştirelim (Hugging Face Trainer beklentisine uygun)\n",
    "    df_cleaned = df_cleaned.rename(columns={label_column: 'labels'})\n",
    "\n",
    "    # Etiketleri sayısal değerlere dönüştürelim ve label_map ile num_labels'ı tanımlayalım\n",
    "    # Etiketler zaten sayısal (int64) olduğu için doğrudan unique değerleri alabiliriz.\n",
    "    unique_labels = df_cleaned['labels'].unique()\n",
    "    # np.int64 objelerini int'e dönüştürelim ki JSON serileştirme veya diğer kullanımlar sorun yaratmasın\n",
    "    label_map = {int(label): i for i, label in enumerate(unique_labels)}\n",
    "    num_labels = len(unique_labels)\n",
    "\n",
    "\n",
    "    print(f\"Etiket Eşlemesi: {label_map}\")\n",
    "    print(f\"Toplam Etiket Sayısı: {num_labels}\")\n",
    "\n",
    "    # Eğitim ve test setlerine ayıralım\n",
    "    # Stratify kullanarak etiket dağılımını eğitim ve test setlerinde benzer tutalım\n",
    "    train_df, test_df = train_test_split(df_cleaned, test_size=0.2, random_state=42, stratify=df_cleaned['labels'])\n",
    "\n",
    "    # Hugging Face Datasets formatına dönüştürelim\n",
    "    # 'Metin' sütununu 'text' olarak yeniden adlandıralım ki tokenizer kolayca işleyebilsin\n",
    "    train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True)).rename_column(\"Metin\", \"text\")\n",
    "    test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True)).rename_column(\"Metin\", \"text\")\n",
    "\n",
    "\n",
    "    # Bir belirteçleyici yükleyelim\n",
    "    # Türkçe için uygun bir model seçelim.\n",
    "    model_checkpoint = \"dbmdz/bert-base-turkish-cased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "    # Veriyi belirteçlere ayıralım\n",
    "    def tokenize_function(examples):\n",
    "        # Tokenizer'ın beklediği formatta metin sütununu kullanalım\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128) # max_length ayarlanabilir\n",
    "\n",
    "    tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "    # Gereksiz sütunları kaldıralım (original text column)\n",
    "    tokenized_train_dataset = tokenized_train_dataset.remove_columns(['text']) # 'text' sütununu kaldırdık\n",
    "    tokenized_test_dataset = tokenized_test_dataset.remove_columns(['text']) # 'text' sütununu kaldırdık\n",
    "\n",
    "\n",
    "    # Formatı ayarlayalım\n",
    "    tokenized_train_dataset.set_format(\"torch\")\n",
    "    tokenized_test_dataset.set_format(\"torch\")\n",
    "\n",
    "\n",
    "    print(\"\\nTokenize Edilmiş Eğitim Veri Seti:\")\n",
    "    print(tokenized_train_dataset)\n",
    "    print(\"\\nTokenize Edilmiş Test Veri Seti:\")\n",
    "    print(tokenized_test_dataset)\n",
    "\n",
    "    # num_labels ve label_map'i de yazdıralım\n",
    "    print(f\"\\nEtiket Eşlemesi (Fine-tuning için): {label_map}\")\n",
    "    print(f\"Toplam Etiket Sayısı (Fine-tuning için): {num_labels}\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame yüklenemediği veya boş olduğu için sonraki adımlar atlandı.\")"
   ],
   "id": "7bea02ebab2b7ee1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "# Sınıf sayısını belirleyelim (veri hazırlığı adımından gelen num_labels değişkeni)\n",
    "# Eğer önceki hücreyi çalıştırmadıysanız veya değişken kaybolduysa buraya manuel olarak atayabilirsiniz.\n",
    "# num_labels = 3 # Örnek değer, veri setinizdeki etiket sayısına göre ayarlayın\n",
    "\n",
    "# Modeli yükleyelim\n",
    "# model_checkpoint değişkeni veri hazırlığı adımından geliyor olmalı.\n",
    "# Eğer gelmiyorsa buraya manuel olarak atayın: model_checkpoint = \"dbmdz/bert-base-turkish-cased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "\n",
    "# Metrik fonksiyonunu tanımlayalım (doğruluk)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Eğitim argümanlarını tanımlayalım\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # Çıktı dizini\n",
    "    learning_rate=2e-5,              # Öğrenme oranı\n",
    "    per_device_train_batch_size=16,  # Cihaz başına eğitim toplu iş boyutu (belleğe göre ayarlayın)\n",
    "    per_device_eval_batch_size=16,   # Cihaz başına değerlendirme toplu iş boyutu (belleğe göre ayarlayın)\n",
    "    num_train_epochs=3,              # Toplam eğitim epoch sayısı (küçük veri seti için yeterli olabilir)\n",
    "    weight_decay=0.01,               # Ağırlık düşürme\n",
    "    eval_strategy=\"epoch\",           # Her epoch sonunda değerlendir\n",
    "    save_strategy=\"epoch\",           # Her epoch sonunda kaydet\n",
    "    load_best_model_at_end=True,     # Eğitim sonunda en iyi modeli yükle\n",
    "    report_to=\"none\",                # Weights & Biases entegrasyonunu kapat\n",
    "    push_to_hub=False,               # Modeli Hugging Face Hub'a yükleme\n",
    ")\n",
    "\n",
    "# Trainer sınıfını oluşturalım\n",
    "# tokenizer değişkeni veri hazırlığı adımından geliyor olmalı.\n",
    "trainer = Trainer(\n",
    "    model=model,                         # Eğitilecek model\n",
    "    args=training_args,                  # Eğitim argümanları\n",
    "    train_dataset=tokenized_train_dataset, # Eğitim veri seti\n",
    "    eval_dataset=tokenized_test_dataset,   # Değerlendirme veri seti\n",
    "    tokenizer=tokenizer,                 # Belirteçleyici\n",
    "    compute_metrics=compute_metrics      # Metrik fonksiyonu\n",
    ")\n",
    "\n",
    "# Modeli fine-tune edelim\n",
    "print(\"Model fine-tuning ediliyor...\")\n",
    "trainer.train()\n",
    "print(\"Fine-tuning tamamlandı.\")"
   ],
   "id": "4a687b374303f881"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Modeli test veri seti üzerinde değerlendirelim\n",
    "print(\"Model değerlendiriliyor...\")\n",
    "evaluation_results = trainer.evaluate()\n",
    "\n",
    "# Değerlendirme sonuçlarını yazdıralım\n",
    "print(\"\\nDeğerlendirme Sonuçları:\")\n",
    "print(evaluation_results)\n",
    "\n",
    "# Özellikle doğruluk (accuracy) gibi metrikleri kontrol edelim\n",
    "if 'eval_accuracy' in evaluation_results:\n",
    "    print(f\"\\nTest Seti Doğruluğu: {evaluation_results['eval_accuracy']:.4f}\")"
   ],
   "id": "73447a01eb9c8401"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# sentence-transformers kütüphanesini kuralım (eğer daha önce kurulmadıysa)\n",
    "!pip install -U sentence-transformers\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch # PyTorch'u içe aktaralım\n",
    "\n",
    "# Kullanılacak embedding modelini yükleyelim.\n",
    "# Türkçe için uygun bir model seçmek önemlidir.\n",
    "# Örneğin: 'paraphrase-multilingual-MiniLM-L12-v2' veya 'sentence-transformers/stsb-bert-base-multilingual-uncased'\n",
    "# Büyük bir veri setiyle çalışıyorsanız, daha küçük bir model seçmek kaynak kullanımı açısından daha iyi olabilir.\n",
    "# Örnek için 'paraphrase-multilingual-MiniLM-L12-v2' kullanalım.\n",
    "embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Bilgi kaynağımızın embeddinglerini oluşturalım\n",
    "# knowledge_source değişkeni bir önceki adımdan geliyor olmalı.\n",
    "if 'knowledge_source' in locals() and len(knowledge_source) > 0:\n",
    "    print(f\"{len(knowledge_source)} adet yorumun embeddingleri oluşturuluyor...\")\n",
    "\n",
    "    # Bellek sorunlarını önlemek için büyük veri setlerini batch'ler halinde işlemek iyi bir fikirdir.\n",
    "    # Ancak bu örnek için doğrudan tüm yorumları işleyelim.\n",
    "    # Eğer bellek hatası alırsanız, burayı batch işlemeye göre yeniden düzenlemeniz gerekebilir.\n",
    "    knowledge_embeddings = embedding_model.encode(knowledge_source, show_progress_bar=True)\n",
    "\n",
    "    print(\"Embedding oluşturma tamamlandı.\")\n",
    "    print(f\"Oluşturulan embeddinglerin şekli: {knowledge_embeddings.shape}\") # (yorum sayısı, embedding boyutu)\n",
    "\n",
    "    # Embeddingleri ve bilgi kaynağını daha sonra kullanmak üzere saklayalım\n",
    "    # knowledge_embeddings ve knowledge_source artık RAG sistemimizin temel bileşenleri.\n",
    "\n",
    "else:\n",
    "    print(\"Bilgi kaynağı (knowledge_source) bulunamadı veya boş. Lütfen bir önceki adımı çalıştırın.\")"
   ],
   "id": "79ff50369e2f293b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Kullanıcı sorgusunu tanımlayalım\n",
    "user_query = \"Ürün kalitesi nasıl?\"\n",
    "\n",
    "# Kullanıcı sorgusunun embeddingini oluşturalım\n",
    "# knowledge_embeddings oluşturmak için kullandığımız aynı modeli kullanalım\n",
    "if 'embedding_model' in locals():\n",
    "    query_embedding = embedding_model.encode([user_query])[0] # Sorgu için embedding oluştur\n",
    "\n",
    "    # Sorgu embeddingi ile bilgi kaynağı embeddingleri arasındaki benzerliği (kosinüs benzerliği) hesaplayalım\n",
    "    # knowledge_embeddings değişkeni bir önceki adımdan geliyor olmalı.\n",
    "    if 'knowledge_embeddings' in locals() and 'knowledge_source' in locals():\n",
    "        print(f\"'{user_query}' sorgusu için ilgili yorumlar aranıyor...\")\n",
    "\n",
    "        # Kosinüs benzerliğini hesapla (vektörlerin normalleştirildiğini varsayarak dot product da kullanılabilir)\n",
    "        # Embeddingler zaten SentenceTransformer tarafından normalleştirilmiş olabilir.\n",
    "        # Güvenli olmak için cosine_similarity kullanalım.\n",
    "        similarities = cosine_similarity([query_embedding], knowledge_embeddings)[0]\n",
    "\n",
    "        # En yüksek benzerliğe sahip yorumların indekslerini alalım\n",
    "        # Örneğin, en ilgili 5 yorumu bulalım\n",
    "        top_k = 5\n",
    "        top_k_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "\n",
    "        print(f\"\\n'{user_query}' sorgusu ile En Benzer (En Alakalı) {top_k} Yorum:\")\n",
    "        retrieved_reviews = [knowledge_source[i] for i in top_k_indices]\n",
    "\n",
    "        for i, review in enumerate(retrieved_reviews):\n",
    "            print(f\"{i+1}. Benzerlik: {similarities[top_k_indices[i]]:.4f} - Yorum: \\\"{review}\\\"\")\n",
    "\n",
    "        # --- Cevap Üretme Simülasyonu ---\n",
    "        # Gerçek RAG sisteminde, bu retrieved_reviews bir dil modeline prompt olarak verilirdi.\n",
    "        # Örneğin: \"Aşağıdaki ürün yorumlarını kullanarak 'Ürün kalitesi nasıl?' sorusuna kısa bir cevap ver:\\n\\n\" + \"\\n\".join(retrieved_reviews)\n",
    "        # Burada basitçe ilgili yorumları bir araya getirerek bir cevap simülasyonu yapalım.\n",
    "\n",
    "        print(\"\\n--- RAG Tabanlı Cevap Simülasyonu ---\")\n",
    "        simulated_answer = \"Kullanıcı yorumlarına göre ürün kalitesi hakkında bazı bilgiler:\\n\\n\" + \"\\n\".join([f\"- {review}\" for review in retrieved_reviews])\n",
    "\n",
    "        print(simulated_answer)\n",
    "        print(\"-\" * 30)\n",
    "        print(\"Not: Bu, ilgili yorumları temel alan basit bir simülasyondur. Gerçek bir RAG modeli daha akıcı ve bağlamsal cevaplar üretecektir.\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Bilgi kaynağı embeddingleri (knowledge_embeddings) veya bilgi kaynağı (knowledge_source) bulunamadı. Lütfen önceki adımları çalıştırın.\")\n",
    "\n",
    "else:\n",
    "    print(\"Embedding modeli (embedding_model) bulunamadı. Lütfen önceki adımları çalıştırın.\")"
   ],
   "id": "2e7252fdbaf5cd24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Örnek bir yorum seçelim (test setinden veya bilgi kaynağından olabilir)\n",
    "# Örnek olarak RAG sorgusuna benzer bir yorum alalım:\n",
    "sample_review = \"Ürünün hem fiyatı uygun hemde kalitesi çok iyi.\"\n",
    "\n",
    "# Etiket eşlemesini de kullanalım (veri hazırlığı adımından)\n",
    "# Eğer bu hücreyi tek başına çalıştırıyorsanız, label_map'i yeniden tanımlamanız gerekebilir.\n",
    "# label_map = {1: 0, 0: 1, 2: 2} # Örnek değer, kendi label_map'inizle değiştirin\n",
    "# Ters eşlemeyi oluşturalım: id_to_label = {v: k for k, v in label_map.items()}\n",
    "id_to_label = {0: 1, 1: 0, 2: 2} # Modelin çıktısı (0, 1, 2) -> Orijinal etiket (1, 0, 2)\n",
    "\n",
    "\n",
    "# Yorumu tokenize edelim\n",
    "inputs = tokenizer(sample_review, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# Modeli ve girdi tensörlerini aynı cihaza taşıyalım (GPU varsa 'cuda', yoksa 'cpu')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "\n",
    "# Tahmin yapalım\n",
    "model.eval() # Modeli değerlendirme moduna alalım\n",
    "with torch.no_grad(): # Gradyan hesaplamayı kapat\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    predicted_label_id = predictions.item()\n",
    "    predicted_sentiment = id_to_label[predicted_label_id]\n",
    "\n",
    "\n",
    "print(f\"Örnek Yorum: \\\"{sample_review}\\\"\")\n",
    "print(f\"Fine-tuning Modeli Duygu Tahmini (Sayısal Etiket): {predicted_label_id}\")\n",
    "# Etiket eşlemesini kullanarak anlamlı etiketi yazdıralım\n",
    "print(f\"Fine-tuning Modeli Duygu Tahmini (Orijinal Etiket): {predicted_sentiment}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Karşılaştırma ---\")\n",
    "\n",
    "# Daha önceki RAG simülasyonu çıktısını hatırlayalım\n",
    "# user_query ve simulated_answer değişkenlerinin önceki hücrelerden geldiğini varsayıyoruz.\n",
    "if 'user_query' in locals() and 'simulated_answer' in locals():\n",
    "    print(f\"Daha önceki RAG Sorgusu: '{user_query}'\")\n",
    "    print(\"RAG Simülasyonu Çıktısı (İlgili Yorumları Getirme ve Özetleme):\")\n",
    "    print(simulated_answer) # RAG simülasyonundan gelen değişken\n",
    "else:\n",
    "    print(\"RAG simülasyonu değişkenleri (user_query, simulated_answer) bulunamadı. Lütfen RAG simülasyonu adımını çalıştırın.\")\n",
    "\n",
    "\n",
    "print(\"\\nFark:\")\n",
    "print(\"Fine-tuning modeli, doğrudan yorumun duygu sınıfını (pozitif, negatif, nötr vb.) tahmin etti.\")\n",
    "print(\"RAG simülasyonu ise, sorguyla ilgili yorumları bilgi kaynağından getirdi ve bu yorumları kullanarak bir 'cevap' simüle etti.\")\n",
    "print(\"Fine-tuning metnin genel duygu tonunu anlamaya odaklanırken, RAG belirli bir soruya harici bilgiden faydalanarak yanıt bulmaya odaklanır.\")"
   ],
   "id": "509d4767bc863559"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
